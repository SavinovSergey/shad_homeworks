# shad_homeworks

This repository contains my homework notebooks on the wonderful YSDA NLP [course](https://github.com/yandexdataschool/nlp_course/tree/2025).
# Description
- [transfer](https://github.com/SavinovSergey/shad_homeworks/blob/main/finetune_bert.ipynb) - finetuning DeBERTa-v3-base for the task of recognizing duplicate questions.
- [peft](https://github.com/SavinovSergey/shad_homeworks/blob/main/peft.ipynb) - using prompt-tuning and LoRA for efficient finetuning LLM(Qwen3-4B).
- [quantization](https://github.com/SavinovSergey/shad_homeworks/blob/main/quantization.ipynb) - quantize model for efficient inference: round to nearest, GPTQ.
